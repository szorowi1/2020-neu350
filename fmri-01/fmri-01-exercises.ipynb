{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fMRI Session 01: Solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_theme(style='white', context='notebook', font_scale=1.5)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In today's demonstration, we will show you how to generate the predicted BOLD signal of a simple block design fMRI experiment. In fact, we will be making the predicted BOLD signal for an experiment run by a couple of PNI graduent students a few years ago (more on that later).\n",
    "\n",
    "Today's demonstration will be in three parts: \n",
    "- Part 1: Make the hemodynamic response (HRF) in python\n",
    "- Part 2: Make the predicted BOLD signal using a stimulus function and the HRF\n",
    "- Part 3: Perform a regression analysis on simulated data using the signal from Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 0: Installing `nibabel`/`fmritools`\n",
    "\n",
    "For today and Wednesday's demos, we will be using two fMRI-specific python packages (one written by PNI graduate students): `nibabel` and `fmritools`. To install the packages, open a terminal and run:\n",
    "\n",
    "```bash\n",
    "pip install nibabel\n",
    "pip install git+https://github.com/2019-NEU502b/fmritools.git\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1: Defining the HRF\n",
    "To predict how the BOLD signal should evolve in response to some stimulus, we need to define the shape of the hemodynamic resposne function (HRF). As a reminder, the HRF is the predicted shape of the BOLD signal in response to an instaneous stimulus. Much like the action potential, the canonical HRF has two distinct phases: an initial **rising phase** and a subsequent prolonged **undershoot**. In general, the rising phase peaks around 6s and the trough of the undershoot occurs around 16s. \n",
    "\n",
    "Traditionally, the shape of the HRF is modeled by the superposition of two **[gamma distributions](https://en.wikipedia.org/wiki/Gamma_distribution)**. Neuroscientists use the gamma distribution because it is right-tailed. This asymmetry nicely captures what is typically observed of the HRF.\n",
    "\n",
    "To create a HRF, we will import the `spm_hrf` function from `fmritools`. This function has several parameters that will let you create HRFs of arbitrary shape:\n",
    "\n",
    "- **t1:** Delay of response relative to onset (in seconds), aka the length of the rising phase.\n",
    "- **t2:** Delay of undershoot relative to onset (in seconds).\n",
    "- **d1:** Dispersion of response, or the width of the rising phase.\n",
    "- **d2:** Dispersion of undershoot, or the width of the undershoot.\n",
    "- **ratio:** The size of the response relative to the undershoot.\n",
    "\n",
    "Importantly, the `spm_hrf` function requires the **repetition time (TR)** as its first input. The TR is the sampling frequency of an fMRI experiment, or how often we acquire one complete image of the brain. The TR defines the smoothness of the idealized HRF. \n",
    "\n",
    "In the cell below, try plugging in different values to the `spm_hrf` function and see the HRF it produces. What values of the five parameters above create an HRF that most resembles what you saw in lecture?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fmritools.hrf import spm_hrf\n",
    "\n",
    "## Define repetition time and times.\n",
    "tr = 0.1\n",
    "times = np.arange(0, 32, tr)\n",
    "\n",
    "## PLUG IN VALUES HERE.\n",
    "hrf = spm_hrf(tr, t1=, t2=, d1=, d2=, ratio=)\n",
    "\n",
    "## Plotting.\n",
    "fig, ax = plt.subplots(1,1,figsize=(8,4))\n",
    "ax.plot(times, hrf)\n",
    "ax.set(xlabel='Time (s)', ylabel='AU')\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2: Making the predicted BOLD signal\n",
    "\n",
    "In this second section, we will use the HRF you defined above to generate the predicted BOLD signal in response to a simple block design fMRI experiment. In this experiment, participants were asked alternating blocks of a [visual checkerboard](https://www.youtube.com/watch?v=xEd1h_lz4rA) (warning: flashing lights) and an empty black background. Each stimulus (i.e. checkerboard, blank screen) was presented for 20 seconds a time. \n",
    "\n",
    "In this experiment, participants viewed six total blocks (i.e. 6 checkerboard presentations, 6 background presentations). Images were collected at a rate of 1 acquisition per second (TR=1). Though this paradigm is simple (and boring), we use it because it robustly excites early visual cortex (V1/V2).\n",
    "\n",
    "To generate for this experiment its predicted BOLD signal, we need to perform the following steps:\n",
    "1. Define the (super-sampled) stimulus times.\n",
    "2. Generate the neural \"boxcars\".\n",
    "3. Convolve the boxcar timeseries with the HRF.\n",
    "4. Downsample expected BOLD timeseries.\n",
    "\n",
    "We will perform each step in turn below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [1] Define (super-sampled) times\n",
    "Here we define the sample times of the experiment, or the timestamps when a brain volume (3d brain picture) was collected. Importantly we will define these times in a \"super-sampled\" space. That is, we will act like we acquired far more data points than we actually did. We do this for several reasons. First, it functions to reduce the noisiness of our predicted BOLD signal (more on that in a minute). Second, it allows us to model events that occur between TRs.\n",
    "\n",
    "Though our actual experiment was conducted at TR=1 (i.e. one brain volume per second), we will define our timestamps at TR=0.1 (i.e. 10 brain volumes per second). In the cell below, make a new variable `sst` (for super-sampled times) that contains the timestamp for each sample up to the total length of the experiment (remember: the experiment is comprised of 12 blocks of stimuli, each 20s long)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [2] Generate boxcar function\n",
    "\n",
    "In this step, we define a \"boxcar\" timeseries. The boxcar timeseries is made up of 0s and 1s corresponding to when a stimulus was absent and present, respectively. The epochs when the timeseries is 1 is a period of time we predict neurons to be active, eliciting a BOLD response. \n",
    "\n",
    "Below we will only generate only one boxcar timeseries, corresponding to the onset and offset of the visual checkerboard. This is because we will assume that the brain is inactive during the presentation of the blank background screen. (Do you think this a good assumption?)\n",
    "\n",
    "In the cell below, define the onsets and offsets (in seconds) of each block of visual checkerboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, make a new array, `boxcars`, the same length of `sst` that is comprised entirely of zeros. (Hint: you can use `np.zeros_like`). Then using `sst` and the onsets/offsets you defined, index into this array and set all samples corresponding to a checkerboard event to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot this new array to see what it looks like. Does it look like boxcars? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [3] Convolution\n",
    "Convolution describes a particular mathematical operation where we use two functions to produce a third function that expresses how the shape of one is modified by the other. A nice visual illustration of convolution is [shown here](https://larzeitlin.github.io/images/3.3.gif). In this case, we convolve the boxcars with the HRF to model how we expect the BOLD signal to change in response to the checkerboard stimulus.\n",
    "\n",
    "To perform convolution, we will use `np.convolve` inserting our `boxcars` array first, followed by `hrf`. Store the output of this operation in a new variable, `bold`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we perform two small steps: First, you may notice the new variable `bold` is longer than `sst`. This is an artifact of the convolution. Make `bold` as long as `sst` by trimming the last N samples from the array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second, we normalize `bold` so that its max value is equal to 1. (This will help us in the regression below.) Normalize `bold` by dividing it by its current max value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot this new array relative to boxcars. How does it look?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [4] Downsampling\n",
    "In this final step, we reduce the convolved timeseries to only those observations that we actually acquired. In other words, we convert the `bold` array from TR=0.1 to TR=1.0.\n",
    "\n",
    "The logic and syntax for this step is rather annoying, so we have provided some code below. In short, we define the timestamps of the data we collected, `times` (e.g. 0, 1, 2, ...). Then we find the indices of the corresponding timestamps in `sst`. Finally, we use these indices to downsample `boxcars` and `bold`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define observation times.\n",
    "tr = 1\n",
    "times = np.arange(n_times) * tr\n",
    "\n",
    "## Define downsampling indices.\n",
    "ix = np.in1d(sst, times)\n",
    "\n",
    "## Downsampling.\n",
    "boxcars = boxcars[ix]\n",
    "bold = bold[ix]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the new `boxcars` and `bold` on the Y-axis, and `times` on the X-axis to confirm this procedure worked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3: Regression on simulated data\n",
    "\n",
    "In this final section for today, we will use the predicted BOLD signal you generated and use it to perform linear regression with simulated BOLD data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [1] Load and visualize data\n",
    "\n",
    "In this step we will load in some data simulated to look like actual BOLD data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load and extract data.\n",
    "npz = np.load('fmri-01-data.npz')\n",
    "\n",
    "## Extract the times and simulated data.\n",
    "times = npz['times']\n",
    "y = npz['y']\n",
    "print('times:', times.shape)\n",
    "print('y:', y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variable `y` is a matrix of simulated fMRI voxels, or 20 BOLD timeseries each 240s long. The simulated data have been normalized to be in the units of **percent signal change**. In other words, the magnitude of each value correspond to how many percent the signal changes from baseline.\n",
    "\n",
    "Plot the simulated data below. Does it look like the predicted BOLD timeseries?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [2] Construct design matrix\n",
    "\n",
    "In statistics, a design matrix, `X`, (also known as model matrix or regressor matrix), is a matrix of values of explanatory variables of a set of objects. That is, its a set of timeseries we use to predict our observed (simulated) BOLD data.\n",
    "\n",
    "In our case, our design matrix will be comprised of two arrays: an *intercept* and `bold` timeseries. The intercept is just an array made entirely of 1s. Using `np.ones_like` and `np.column_stack`, make our design matrix `X` in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [3] Regression\n",
    "\n",
    "In this final step, we will regress our design matrix against the simulated BOLD data. In our regression, we will solve for **coefficients** that map each regressor (i.e. column in the design matrix) to the observed data. Importantly, the coefficients tell us by how much our regressors need to be scaled to best predict the data. In our case, the coefficients tell us by how many percent the BOLD signal of one voxel changed in response to the checkerboard stimulus.\n",
    "\n",
    "To perform the regression, we use `np.linalg.lstsq`. We provide the syntax below. The coefficients are stored in `coef`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Perform regression.\n",
    "coef, _, _, _ = np.linalg.lstsq(X, y, rcond=-1)\n",
    "print(coef.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a histogram of the coefficients corresponding to our predicted BOLD signal. By how many percent did the simulated BOLD signal change in response to the visual checkerboard?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
